# Supabase Database Optimization Guide

## ‚ö†Ô∏è Memory Error Solution

The error `memory required is 63 MB, maintenance_work_mem is 32 MB` occurs when trying to create vector indexes that exceed Supabase's memory limits.

### Error: "memory required is 60 MB, maintenance_work_mem is 32 MB"
**Cause**: Vector index creation requires more memory than Supabase provides

**Solutions (try in order):**
1. Use micro vector index: `\i scripts/optimization-step-3-micro.sql`
2. Skip vector index entirely: `\i scripts/optimization-step-3-no-vector.sql`  
3. Upgrade Supabase plan for more memory
4. Reduce dataset size before creating index

**Result**: System falls back to text search (still functional, slightly slower)

## üîß Safe Optimization Steps

### Option 1: Run the Safe All-in-One Script
Use the Supabase-optimized script that respects memory constraints:

```sql
-- Run this single script
\i scripts/15-supabase-safe-optimization.sql
```

### Option 2: Step-by-Step Optimization (Recommended)
Run these scripts **one at a time** to avoid memory issues:

#### Step 1: Cleanup and Analysis
```sql
\i scripts/optimization-step-1.sql
```
**What it does**: Cleans old cache entries and updates table statistics

#### Step 2: Essential Indexes  
```sql
\i scripts/optimization-step-2-safe.sql
```
**What it does**: Creates basic lookup indexes (safe for PostgreSQL immutable function constraints)

#### Step 3: Vector Index (Memory Intensive)

**Choose ONE of these options based on your Supabase plan:**

**Option A: Try minimal vector index (recommended first)**
```sql
\i scripts/optimization-step-3-micro.sql
```

**Option B: Skip vector index entirely (if Option A fails)**  
```sql
\i scripts/optimization-step-3-no-vector.sql
```

**Option C: Conservative approach (if you have data > 500 rows)**
```sql
\i scripts/optimization-step-3.sql
```

**What it does**: Attempts vector index creation with automatic fallback to text search

#### Step 4: Functions and Maintenance
```sql
\i scripts/optimization-step-4.sql
```
**What it does**: Creates optimized functions and sets maintenance parameters

## üõ† Before Running Optimizations

Check your current data size:
```sql
SELECT 
    'textbook_embeddings' as table_name,
    COUNT(*) as row_count,
    pg_size_pretty(pg_total_relation_size('textbook_embeddings')) as size
FROM textbook_embeddings
UNION ALL
SELECT 
    'content_cache',
    COUNT(*),
    pg_size_pretty(pg_total_relation_size('content_cache'))
FROM content_cache;
```

## üìä Memory-Conscious Approach

The optimized scripts use these strategies:

### Vector Index Optimization
- **Old approach**: Fixed 200 lists (high memory usage)
- **New approach**: Dynamic lists based on data size (max 25 for Supabase)
- **Formula**: `LEAST(row_count / 20, 20)` lists

### Index Strategy
- Create only essential indexes first
- Use partial indexes for hot data
- Avoid complex composite indexes

### Memory Management
- Clean old cache entries before optimization
- Use conservative autovacuum settings
- Create simple views instead of materialized views

## üîç Verification

After running optimizations, check the results:

```sql
-- Check indexes
SELECT schemaname, tablename, indexname, indexdef 
FROM pg_indexes 
WHERE tablename IN ('textbook_embeddings', 'content_cache', 'query_embedding_cache')
ORDER BY tablename, indexname;

-- Check table sizes
SELECT 
    table_name,
    pg_size_pretty(pg_total_relation_size(table_name::regclass)) as size
FROM (VALUES ('textbook_embeddings'), ('content_cache'), ('query_embedding_cache')) 
AS t(table_name);

-- Check function
SELECT routine_name, routine_type 
FROM information_schema.routines 
WHERE routine_name LIKE '%textbook%' 
AND routine_schema = 'public';
```

## üö® If You Still Get Memory Errors

1. **Check your Supabase plan**: Free tier has lower memory limits
2. **Reduce data size**: Delete old/unused embeddings
3. **Skip vector index**: Run only steps 1, 2, and 4
4. **Contact Supabase**: They may be able to temporarily increase memory limits

## üéØ Expected Performance Improvements

Even with conservative settings, you should see:
- **50-70% faster** textbook searches
- **30-50% better** cache performance  
- **Reduced** database load
- **Better** query planning with updated statistics

## üìà Monitoring

Check optimization effectiveness:
```sql
-- Search performance test
SELECT search_similar_textbook_content_optimized(
    (SELECT embedding FROM textbook_embeddings LIMIT 1),
    3, -- grade level
    0.6, -- threshold
    5 -- limit
);

-- Cache statistics
SELECT * FROM textbook_content_stats;
```

## üîÑ Maintenance

Run periodically (monthly):
```sql
-- Update statistics
ANALYZE textbook_embeddings;
ANALYZE content_cache;

-- Clean old cache
DELETE FROM content_cache WHERE created_at < NOW() - INTERVAL '30 days';
```

## ‚ö° Quick Fix for Current Error

If you just want to fix the immediate error:

```sql
-- Drop the problematic index creation from the original script
DROP INDEX IF EXISTS textbook_embeddings_embedding_optimized_idx;

-- Create a minimal vector index instead
CREATE INDEX textbook_embeddings_vector_minimal_idx
ON textbook_embeddings 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 10); -- Very small for memory safety
```

This will give you basic vector search functionality without memory errors.

## ‚ö†Ô∏è Common PostgreSQL Errors and Solutions

### Error: "functions in index predicate must be marked IMMUTABLE"
**Cause**: Using `NOW()` or other non-immutable functions in index WHERE clauses

**Solution**: 
- Use fixed timestamps instead of `NOW()`
- Remove time-based predicates from indexes
- Use simple indexes without date filters

**Fixed in**: `optimization-step-2-safe.sql`

## üìä Supabase Plan Recommendations

### Free Tier (32MB maintenance_work_mem)
- ‚úÖ Use optimization steps 1, 2, 4
- ‚ùå Skip vector indexes (use text search fallback)
- üìà Expected performance: 70% improvement

### Pro Tier (Higher memory limits)
- ‚úÖ All optimization steps  
- ‚úÖ Small vector indexes (< 1000 embeddings)
- üìà Expected performance: 90% improvement

### Enterprise Tier
- ‚úÖ Full vector optimization
- ‚úÖ Large datasets supported
- üìà Expected performance: 95% improvement
